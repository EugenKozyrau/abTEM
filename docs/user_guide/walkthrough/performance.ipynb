{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a68d55-5e9b-4bab-b324-05b89a56cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abtem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbed61-5e88-4ec3-9c2a-83a0d70f2ba8",
   "metadata": {},
   "source": [
    "# Performance, parallelization and GPUs\n",
    "\n",
    "The cost of running simulations of transmission electron microscopy can range from seconds to months depending on factors such as sample size, number of probe positions and the hardware used to run the code. Here, we go through how optimize *abTEM* to get your simulations running as fast as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c74ed-dfb6-4426-898a-63110b6fb253",
   "metadata": {},
   "source": [
    "## FFTs \n",
    "\n",
    "The [fast Fourier transform (FFT)](https://en.wikipedia.org/wiki/Fast_Fourier_transform) is the most important depending algorithm for running the multislice algorithm. Hence, the speed of your simulation depends on how fast your computer can run the FFT. This will depend on your hardware, the implementation of the FFT and the grid points of your simulation.  \n",
    "\n",
    "### FFT Library (only on CPU)\n",
    "*abTEM* provides two implementations of the FFT: Intels Math Kernel Library FFT ([`mkl_fft`](https://github.com/IntelPython/mkl_fft)) and the \"Fastest Fourier Transform in the West\" (FFTW) through the Python wrapper [`pyfftw`].(https://pyfftw.readthedocs.io/en/latest/). You can set the FFT library \n",
    "\n",
    "*abTEM* currently supports NVidia GPUs, hence  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ae446-a875-42ae-b7a0-b3efadc1f110",
   "metadata": {},
   "source": [
    "abtem.config.set({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2aaf0-80a0-4058-99a2-faa12025ab42",
   "metadata": {},
   "source": [
    "## Dask\n",
    "\n",
    "*abTEM* is parallelized using [Dask](https://dask.org/) {cite}`dask`. *abTEM* builds a *Dask* task graph for your simulation which is executed using one of the *Dask* schedulers.  \n",
    "\n",
    "On a local system (a laptop or desktop), your is parallelized automatically using [threads](https://docs.dask.org/en/stable/scheduling.html#local-threads). Nonetheless, you may benefit from knowing about \n",
    "\n",
    "*abTEM* uses the \n",
    "\n",
    "as *abTEM\n",
    "\n",
    "\n",
    "https://docs.dask.org/en/stable/scheduling.html\n",
    "\n",
    "Parallel computation in abTEM whether it is running on a laptop or a High Performance Computing cluster is parallelized through . \n",
    "\n",
    "Some knowledge of Dask may be required to run abTEM effectively on large multi-CPU/GPU systems, however, if you are just running abTEM on your own computer, this tutorial gets you started. If you want a quick introduction to Dask, we recommend thishttps://www.youtube.com/watch?v=nnndxbr_Xq4&t=66s) short youtube video.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c1f0d-1fb3-4d1a-aa07-ae5403295056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e39cb8d2-a898-478d-9831-275ac5f2f06b",
   "metadata": {},
   "source": [
    "## GPUs\n",
    "\n",
    "Almost every part . This is possible through"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a149494a-31fb-4908-97c5-0ab1ed750e9b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fb55621-1727-438b-ad12-f881c9a3274a",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abtem-dask",
   "language": "python",
   "name": "abtem-dask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
